"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              EEG Channel Expansion - Google Colab Training
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Repository: https://github.com/rusty-saber/EEG-project

ARCHITECTURE:
â”œâ”€ GitHub Repository (code):
â”‚  â”œâ”€ src/ (source code)
â”‚  â”œâ”€ scripts/ (training scripts)
â”‚  â””â”€ configs/ (configuration files)
â”‚
â””â”€ colab_data.zip (data only):
   â””â”€ data/processed/ (109 preprocessed .npz files)

BEFORE STARTING:
1. Runtime â†’ Change runtime type â†’ GPU (T4 or A100)
2. Have colab_data.zip ready on your computer (~287MB)
   Location: channel expansion/colab_data.zip

TRAINING TIME: 5-10 hours on T4 GPU
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 1: Verify GPU
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import torch
print("="*70)
print("Checking GPU...")
print("="*70)
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"âœ… GPU: {gpu_name}")
    print(f"   Memory: {gpu_mem:.1f} GB")
else:
    print("âŒ NO GPU DETECTED!")
    print("\nFix: Runtime â†’ Change runtime type â†’ GPU (T4) â†’ Save")
    raise RuntimeError("GPU required for training")
print("="*70)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 2: Install Dependencies (~1 minute)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nInstalling dependencies...")
!pip install -q torch torchvision torchaudio
!pip install -q mne transformers==4.44.0 omegaconf tqdm scipy numpy
print("âœ… Dependencies installed\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 3: Clone Repository (gets code ONLY, no data)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("="*70)
print("Cloning repository from GitHub...")
print("="*70)
!rm -rf /content/EEG-project  # Clean up if exists
!git clone https://github.com/rusty-saber/EEG-project.git /content/EEG-project
print("âœ… Repository cloned")

# Verify code files exist
import os
code_check = {
    'src': os.path.isdir('/content/EEG-project/src'),
    'scripts': os.path.isdir('/content/EEG-project/scripts'),
    'configs': os.path.isdir('/content/EEG-project/configs'),
}
print("\nCode verification:")
for name, exists in code_check.items():
    status = "âœ…" if exists else "âŒ"
    print(f"  {status} {name}/")

if not all(code_check.values()):
    print("\nâŒ ERROR: Repository is incomplete!")
    raise FileNotFoundError("Source code directories missing from repository")
print("="*70 + "\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 4: Upload Data File (colab_data.zip contains ONLY data/processed/)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from google.colab import files

print("="*70)
print("UPLOAD DATA FILE")
print("="*70)
print("In the file picker:")
print("1. Navigate to: channel expansion/")
print("2. Select: colab_data.zip (~287MB)")
print("3. Click 'Open' and wait for upload (2-5 minutes)")
print("="*70)
print("\n[File picker will appear below]")
print("="*70 + "\n")

# Upload to /content (Colab's working directory)
os.chdir('/content')
uploaded = files.upload()

# Verify upload
if 'colab_data.zip' not in uploaded:
    print("\nâŒ ERROR: Wrong file uploaded!")
    print("Expected: colab_data.zip")
    print(f"Got: {list(uploaded.keys())}")
    raise FileNotFoundError("Please upload colab_data.zip")

file_size_mb = len(uploaded['colab_data.zip']) / (1024*1024)
print(f"\nâœ… Upload successful!")
print(f"   File: colab_data.zip")
print(f"   Size: {file_size_mb:.1f} MB")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 5: Extract Data into Project Directory
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "="*70)
print("Extracting data...")
print("="*70)

import zipfile

try:
    # Extract zip contents to project directory
    with zipfile.ZipFile('/content/colab_data.zip', 'r') as zip_ref:
        # List contents
        file_list = zip_ref.namelist()
        print(f"Zip contains {len(file_list)} files")
        
        # Extract to project
        zip_ref.extractall('/content/EEG-project/')
        print("âœ… Extraction complete")
        
except zipfile.BadZipFile:
    print("âŒ ERROR: Invalid zip file!")
    raise
except Exception as e:
    print(f"âŒ ERROR during extraction: {e}")
    raise

# Clean up zip file (free up space)
os.remove('/content/colab_data.zip')
print("âœ… Cleanup complete")
print("="*70 + "\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 6: Verify Data
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
os.chdir('/content/EEG-project')

print("="*70)
print("Verifying data integrity...")
print("="*70)

data_dir = 'data/processed'
if not os.path.exists(data_dir):
    print(f"âŒ ERROR: {data_dir} not found!\n")
    print("Directory structure in data/:")
    !ls -R data/
    raise FileNotFoundError(f"{data_dir} missing")

# Count .npz files
npz_files = [f for f in os.listdir(data_dir) if f.endswith('.npz')]
print(f"âœ… Found {len(npz_files)} preprocessed subject files")

# Load statistics if available
import json
stats_file = f'{data_dir}/preprocessing_stats.json'
if os.path.exists(stats_file):
    with open(stats_file) as f:
        stats = json.load(f)
    print(f"   Total segments: {stats.get('total_segments', 'N/A')}")
    print(f"   Valid segments: {stats.get('valid_segments', 'N/A')}")
    print(f"   Rejection rate: {stats.get('rejection_rate', 'N/A'):.1f}%")

print("="*70 + "\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 7: Mount Google Drive (for saving checkpoints)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("="*70)
print("Mounting Google Drive...")
print("="*70)
print("You'll need to:")
print("1. Click the link that appears")
print("2. Sign in to your Google account")
print("3. Copy the authorization code")
print("4. Paste it below")
print("="*70 + "\n")

from google.colab import drive
drive.mount('/content/drive')

# Create checkpoint directory
checkpoint_base = '/content/drive/MyDrive/EEG_Checkpoints'
os.makedirs(checkpoint_base, exist_ok=True)

print(f"\nâœ… Google Drive mounted")
print(f"   Checkpoints will save to: {checkpoint_base}")
print("="*70 + "\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 8: Start Training
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from datetime import datetime

# Create unique run directory
run_name = datetime.now().strftime("run_%Y%m%d_%H%M%S")
output_dir = f"{checkpoint_base}/{run_name}"

print("="*70)
print("ğŸš€ STARTING TRAINING")
print("="*70)
print(f"Run ID: {run_name}")
print(f"Epochs: 100")
print(f"Output: {output_dir}")
print(f"Estimated time: 5-10 hours (T4 GPU)")
print("="*70)
print("\nğŸ’¡ TIP: You can close this tab - training continues in background!")
print("   Checkpoints save to Google Drive automatically every epoch.")
print("\nâ³ Training will start in a few seconds...")
print("="*70 + "\n")

# Run training
!python scripts/run_mvp.py \
    --epochs 100 \
    --skip_download \
    --skip_preprocess \
    --output_dir "{output_dir}"

# Training complete
print("\n" + "="*70)
print("ğŸ‰ TRAINING COMPLETE!")
print("="*70)
print(f"Results saved to: {output_dir}")
print("\nFiles in checkpoint directory:")
!ls -lh "{output_dir}"
print("="*70)

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          OPTIONAL CELLS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CELL A: Monitor Training Progress
Run this in a NEW cell WHILE training is running to see live progress:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
"""
# import glob
# import os
#
# # Find latest run
# runs = sorted(glob.glob('/content/drive/MyDrive/EEG_Checkpoints/run_*'))
# if runs:
#     latest = runs[-1]
#     print(f"Latest run: {latest}")
#     print("\nCheckpoint files:")
#     !ls -lh {latest}
#
#     # Show training log
#     log_path = f"{latest}/training.log"
#     if os.path.exists(log_path):
#         print("\nğŸ“Š Recent training log:")
#         !tail -30 {log_path}
# else:
#     print("No runs found yet")

"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
CELL B: Download Best Model
Run after training completes to download the best checkpoint:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
"""
# from google.colab import files
# import glob
#
# runs = sorted(glob.glob('/content/drive/MyDrive/EEG_Checkpoints/run_*'))
# if runs:
#     latest = runs[-1]
#     model_path = f"{latest}/best_model.pt"
#
#     if os.path.exists(model_path):
#         print(f"Downloading: {model_path}")
#         files.download(model_path)
#         print("âœ… Download complete!")
#     else:
#         print("âŒ best_model.pt not found")
#         print(f"\nAvailable files in {latest}:")
#         !ls -lh {latest}
# else:
#     print("âŒ No checkpoint directories found")

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ISSUE: No GPU detected
â””â”€ FIX: Runtime â†’ Change runtime type â†’ GPU â†’ Save
       Then: Runtime â†’ Disconnect and delete runtime â†’ Reconnect

ISSUE: colab_data.zip upload fails
â””â”€ FIX: Check file is exactly named: colab_data.zip (~287MB)
       Check internet connection
       Try uploading again

ISSUE: "Data directory not found" after extraction
â””â”€ FIX: Verify colab_data.zip contains: data/processed/ folder
       Check zip has 109 .npz files
       Re-download colab_data.zip from local machine

ISSUE: Out of memory during training
â””â”€ FIX: Edit configs/data/physionet.yaml
       Change: batch_size: 4 (reduce from 16)
       Restart from Step 8

ISSUE: Training interrupted
â””â”€ FIX: Checkpoints are saved in Google Drive
       Check: /content/drive/MyDrive/EEG_Checkpoints/
       Find latest run_* directory
       Resume with: scripts/train.py --resume <checkpoint>

ISSUE: Repository clone fails
â””â”€ FIX: Check internet connection
       Verify repository exists: https://github.com/rusty-saber/EEG-project
       Try again: !git clone https://github.com/rusty-saber/EEG-project.git

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        EXPECTED RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After 100 epochs (~5-10 hours):
  â€¢ Mean Pearson r: 0.70-0.75
  â€¢ Mean SNR: 2.5-3.0 dB
  â€¢ Best model: best_model.pt (~300MB)
  â€¢ Checkpoints: Every epoch saved to Drive

Free Colab Tier:
  â€¢ ~12 GPU hours/month
  â€¢ T4 GPU (16GB)
  â€¢ Session timeout: 12 hours (reconnects auto)

Colab Pro ($10/month):
  â€¢ 100 GPU hours/month
  â€¢ Longer sessions
  â€¢ Priority access to better GPUs (V100/A100)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print("\nâœ… Notebook ready! Run Steps 1-8 in order to train.")
